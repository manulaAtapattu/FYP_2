import torchtext
import spacy
from torchtext import data
import re

# tokenizer function using spacy
nlp = spacy.load('en',disable=['parser', 'tagger', 'ner'])
def tokenizer(s):
    return [w.text.lower() for w in nlp(tweet_clean(s))]

def tweet_clean(text):
    text = re.sub(r'[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric character
    text = re.sub(r'https?:/\/\S+', ' ', text) # remove links
    return text.strip()

# define the columns that we want to process and how to process
txt_field = data.Field(sequential=True,
                       tokenize=tokenizer,
                       include_lengths=True,
                       use_vocab=True)
label_field = data.Field(sequential=False,
                         use_vocab=False,
                         pad_token=None,
                         unk_token=None)

train_val_fields = [
    ('text', txt_field), # process it as label
    ('label', label_field) # process it as text
]

trainds, valds = data.TabularDataset.splits(path='data',
                                            format='csv',
                                            train='csvTest.csv',
                                            validation='csvTest.csv',
                                            fields=train_val_fields,
                                            skip_header=True)

print('finished')